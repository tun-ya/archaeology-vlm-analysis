{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9935a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae5413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset that has all the scraped data\n",
    "df = pd.read_csv(\"final_scraped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54c1306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22750, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef0bdc8",
   "metadata": {},
   "source": [
    "The path column is inconsistent. Let's fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85df5d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          images\\10005.jpg\n",
       "1                          images\\10006.jpg\n",
       "2                          images\\10007.jpg\n",
       "3                          images\\10115.jpg\n",
       "4                          images\\10121.jpg\n",
       "                        ...                \n",
       "22745    /collections/assets/199240_800.jpg\n",
       "22746    /collections/assets/569000_800.jpg\n",
       "22747    /collections/assets/568903_800.jpg\n",
       "22748    /collections/assets/142255_800.jpg\n",
       "22749    /collections/assets/142238_800.jpg\n",
       "Name: image_path, Length: 22750, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98952cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the paths\n",
    "def normalize_image_path(path):\n",
    "    # Replace backslashes with forward slashes\n",
    "    path = path.replace(\"\\\\\", \"/\")\n",
    "    \n",
    "    # Ensure the path starts with 'images/'\n",
    "    if not path.startswith(\"images/\"):\n",
    "        # Get the image file name (last part of the path)\n",
    "        image_name = path.split(\"/\")[-1]\n",
    "        # Reconstruct the correct path\n",
    "        path = f\"images/{image_name}\"\n",
    "    \n",
    "    return path\n",
    "\n",
    "# Apply the function to the 'image_path' column\n",
    "df['image_path'] = df['image_path'].apply(normalize_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98b8449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             images/10005.jpg\n",
       "1             images/10006.jpg\n",
       "2             images/10007.jpg\n",
       "3             images/10115.jpg\n",
       "4             images/10121.jpg\n",
       "                 ...          \n",
       "22745    images/199240_800.jpg\n",
       "22746    images/569000_800.jpg\n",
       "22747    images/568903_800.jpg\n",
       "22748    images/142255_800.jpg\n",
       "22749    images/142238_800.jpg\n",
       "Name: image_path, Length: 22750, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7981aae",
   "metadata": {},
   "source": [
    "Name or Object Title is an important attribute and during webscraping we couldn't get the titles for some artifacts.\n",
    "Dropping the rows with null object title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5885d580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdb6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc938cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e5c25",
   "metadata": {},
   "source": [
    "Some artifacts didn't have very specific object titles but a general name. For each artifact that has an object title, we keep the object title, else we replace the null values with the general name of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f41b6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Object Title'] = df['Object Title'].fillna(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67da66bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Object Title'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03a3b1",
   "metadata": {},
   "source": [
    "The column 'name' is not redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dcb09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4bf4e",
   "metadata": {},
   "source": [
    "Some other columns are also irrelevant for our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b085f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Current Location','Depth', 'Height', 'Length', 'Other Number', 'Outside Diameter', \n",
    "                              'Thickness', 'Width'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac3afc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22680, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bfb7c",
   "metadata": {},
   "source": [
    "Now using NLP, we can extract some information from the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94f6392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Description'].str.strip().fillna('No description available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "860e9b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Object Number                                        Description Culture d  \\\n",
      "0         10005           Showing artificial and natural fracture.      None   \n",
      "1         10006                           No description available      None   \n",
      "2         10007                           No description available      None   \n",
      "3         10115  The fragment of pottery is unusually thick, an...      None   \n",
      "4         10121                                         Spade like      None   \n",
      "\n",
      "  Date Made d Iconography d Materials d Period d Provenience d Technique d  \n",
      "0        None          None        None     None          None        None  \n",
      "1        None          None        None     None          None        None  \n",
      "2        None          None        None     None          None        None  \n",
      "3        None          None        None     None     Tennessee        None  \n",
      "4        None          None        None     None          None        None  \n"
     ]
    }
   ],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Keep the 'Object Number' column as well\n",
    "df_nlp = df[['Object Number', 'Description']].copy()  # Create a deep copy\n",
    "\n",
    "# Convert the 'Description' column to strings (handle NaN values as 'nan')\n",
    "df_nlp['Description'] = df_nlp['Description'].astype(str)\n",
    "\n",
    "def extract_entities(description):\n",
    "    # Process the description with spaCy\n",
    "    doc = nlp(description)\n",
    "    \n",
    "    # Initialize a dictionary to store extracted entities (set to None if not found)\n",
    "    entities = {\n",
    "        'Culture d': None,\n",
    "        'Date Made d': None,\n",
    "        'Iconography d': None,\n",
    "        'Materials d': None,\n",
    "        'Period d': None,\n",
    "        'Provenience d': None,\n",
    "        'Technique d': None\n",
    "    }\n",
    "    \n",
    "    # Extract entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'MATERIAL':  # Materials\n",
    "            entities['Materials d'] = ent.text\n",
    "        elif ent.label_ == 'CULTURE':  # Culture\n",
    "            entities['Culture d'] = ent.text\n",
    "        elif ent.label_ == 'DATE' or ent.label_ == 'CARDINAL':  # Date Made / Period\n",
    "            entities['Date Made d'] = ent.text\n",
    "        elif ent.label_ == 'ORG':  # Iconography (assuming some organization references)\n",
    "            entities['Iconography d'] = ent.text\n",
    "        elif ent.label_ == 'GPE':  # Provenience (Geopolitical locations)\n",
    "            entities['Provenience d'] = ent.text\n",
    "        elif ent.label_ == 'TIME':  # Period (time reference)\n",
    "            entities['Period d'] = ent.text\n",
    "        elif ent.label_ == 'SKILL' or ent.label_ == 'MATERIAL':  # Technique (sometimes overlaps with Material or Skill)\n",
    "            entities['Technique d'] = ent.text\n",
    "    \n",
    "    # Return the updated dictionary\n",
    "    return entities\n",
    "\n",
    "# Apply the function to the 'Description' column\n",
    "df_nlp['Entities'] = df_nlp['Description'].apply(extract_entities)\n",
    "\n",
    "# Expand the 'Entities' dictionary into separate columns\n",
    "for col in df_nlp['Entities'][0].keys():  # Use df_nlp here, not df\n",
    "    df_nlp[col] = df_nlp['Entities'].apply(lambda x: x[col])\n",
    "\n",
    "# Optionally drop the 'Entities' column as it is now expanded\n",
    "df_nlp.drop(columns=['Entities'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame for the first 5 rows\n",
    "print(df_nlp.head(5))  # Display first 5 rows\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df_nlp.to_csv(\"info_from_description.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1eed5",
   "metadata": {},
   "source": [
    "This information is stored in \"info from description.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b62bc",
   "metadata": {},
   "source": [
    "Let's see how much valuable information does this df have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e422da2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22680, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09e81f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Number        0\n",
      "Description          0\n",
      "Culture d        22680\n",
      "Date Made d      14496\n",
      "Iconography d    16970\n",
      "Materials d      22680\n",
      "Period d         22657\n",
      "Provenience d    19605\n",
      "Technique d      22680\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_values = df_nlp.isna().sum()\n",
    "\n",
    "# Display the number of null values for each column\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d99dd",
   "metadata": {},
   "source": [
    "We can see that Date Made, Iconography, Period and Provenience are the only columns that have at least some not null values that might be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7aa4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp.drop(columns=['Culture d', 'Materials d', 'Technique d'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146658e",
   "metadata": {},
   "source": [
    "Now let's concatinate this with the data that we have and merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c013fe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22680, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff3fe9",
   "metadata": {},
   "source": [
    "They have the same number of rows and as we didn't manipulate the rows, we can simply concatinate the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4946b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_nlp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f976c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Object Number', 'image_path', 'Archaeology Area', 'Creator',\n",
       "       'Credit Line', 'Culture Area', 'Culture', 'Date Made', 'Description',\n",
       "       'Iconography', 'Inscription Language', 'Locus', 'Manufacture Location',\n",
       "       'Materials', 'Native Name', 'Object Title', 'Period', 'Provenience',\n",
       "       'Section', 'Site Name', 'Subject', 'Technique', 'Object Number',\n",
       "       'Description', 'Date Made d', 'Iconography d', 'Period d',\n",
       "       'Provenience d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0458f95",
   "metadata": {},
   "source": [
    "Object Number and Description are redundant so we remove that and save the dataframe as csv to not lose our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e769477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: Index(['Object Number', 'Description'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Find duplicated columns\n",
    "duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "\n",
    "# Drop duplicated columns, keeping only the first occurrence\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Alternatively, if you want to keep track of which columns were dropped:\n",
    "print(f\"Dropped columns: {duplicate_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c1a610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Concatinated with NLP columns.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4141ebb",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2306d",
   "metadata": {},
   "source": [
    "Reload again to help me later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "89f4daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Concatinated with NLP columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ef674d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object Number               0\n",
       "image_path                  0\n",
       "Archaeology Area        19504\n",
       "Creator                 22049\n",
       "Credit Line               559\n",
       "Culture Area            14991\n",
       "Culture                 12188\n",
       "Date Made               14992\n",
       "Description                 0\n",
       "Iconography             18967\n",
       "Inscription Language    21385\n",
       "Locus                   17677\n",
       "Manufacture Location    21713\n",
       "Materials                 288\n",
       "Native Name             21827\n",
       "Object Title                0\n",
       "Period                  15622\n",
       "Provenience               149\n",
       "Section                     0\n",
       "Site Name               22140\n",
       "Subject                 22667\n",
       "Technique               18097\n",
       "Date Made d             14496\n",
       "Iconography d           16970\n",
       "Period d                22657\n",
       "Provenience d           19605\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b87a5",
   "metadata": {},
   "source": [
    "Getting rid of columns that have mostly null values and are not as relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ba7a22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Creator', 'Credit Line', 'Inscription Language', 'Manufacture Location',\n",
    "                                      'Native Name', 'Site Name', 'Subject'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3a211c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22680, 19)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bfe63f",
   "metadata": {},
   "source": [
    "Fill null values in our original columns from the data we got from the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1211055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'Date Made' with 'Date Made d' where 'Date Made' is NaN\n",
    "df['Date Made'] = df['Date Made'].fillna(df['Date Made d'])\n",
    "\n",
    "# Fill missing values in 'Iconography' with 'Iconography d' where 'Iconography' is NaN\n",
    "df['Iconography'] = df['Iconography'].fillna(df['Iconography d'])\n",
    "\n",
    "df['Period'] = df['Period'].fillna(df['Period d'])\n",
    "\n",
    "df['Provenience'] = df['Provenience'].fillna(df['Provenience d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "61b3254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object Number           0\n",
       "image_path              0\n",
       "Archaeology Area    19504\n",
       "Culture Area        14991\n",
       "Culture             12188\n",
       "Date Made           10422\n",
       "Description             0\n",
       "Iconography         14782\n",
       "Locus               17677\n",
       "Materials             288\n",
       "Object Title            0\n",
       "Period              15604\n",
       "Provenience           141\n",
       "Section                 0\n",
       "Technique           18097\n",
       "Date Made d         14496\n",
       "Iconography d       16970\n",
       "Period d            22657\n",
       "Provenience d       19605\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3aab4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Date Made d', 'Iconography d', 'Period d', 'Provenience d'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25657183",
   "metadata": {},
   "source": [
    "Dropping some more columns that have a lot of null values and it is hard to fill them accurately. Plus they are not very useful for taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "12e9e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Archaeology Area', 'Locus', 'Technique'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7b820",
   "metadata": {},
   "source": [
    "And let's drop some rows that have a lot of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8642699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows where all columns except are null:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "excluded_columns = ['Object Number', 'image_path', 'Description', 'Object Title', 'Section']\n",
    "\n",
    "# Create a mask for rows where all columns except the excluded ones are null\n",
    "mask = df.drop(columns=excluded_columns).isna().all(axis=1)\n",
    "\n",
    "# Step 2: Filter and display rows that match the condition\n",
    "rows_with_nulls_except_specified = df[mask]\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nRows where all columns except are null:\")\n",
    "print(rows_with_nulls_except_specified.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5f196fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object Number        0\n",
       "image_path           0\n",
       "Culture Area     14991\n",
       "Culture          12188\n",
       "Date Made        10422\n",
       "Description          0\n",
       "Iconography      14782\n",
       "Materials          288\n",
       "Object Title         0\n",
       "Period           15604\n",
       "Provenience        141\n",
       "Section              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7e29f1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows where all columns except are null:\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "excluded_columns = ['Object Number', 'image_path', 'Description', 'Object Title', 'Section', 'Provenience']\n",
    "\n",
    "# Create a mask for rows where all columns except the excluded ones are null\n",
    "mask = df.drop(columns=excluded_columns).isna().all(axis=1)\n",
    "\n",
    "# Step 2: Filter and display rows that match the condition\n",
    "rows_with_nulls_except_specified = df[mask]\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nRows where all columns except are null:\")\n",
    "print(rows_with_nulls_except_specified.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9cb0d3",
   "metadata": {},
   "source": [
    "We can lose 25 data points, no problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a50c3ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22655"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(index=df[mask].index, inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5c7d2377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows where all columns except are null:\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "excluded_columns = ['Object Number', 'image_path', 'Description', 'Object Title', 'Section', 'Provenience', 'Materials']\n",
    "\n",
    "# Create a mask for rows where all columns except the excluded ones are null\n",
    "mask = df.drop(columns=excluded_columns).isna().all(axis=1)\n",
    "\n",
    "# Step 2: Filter and display rows that match the condition\n",
    "rows_with_nulls_except_specified = df[mask]\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nRows where all columns except are null:\")\n",
    "print(rows_with_nulls_except_specified.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c5679",
   "metadata": {},
   "source": [
    "We can lose 2023 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c5db88a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20632"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(index=df[mask].index, inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46188a6",
   "metadata": {},
   "source": [
    "# Using mode to fill in the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "64a6c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section             10\n",
      "Culture Area        59\n",
      "Period             856\n",
      "Culture           1213\n",
      "Materials         2448\n",
      "Date Made         2582\n",
      "Provenience       2596\n",
      "Object Title      2803\n",
      "Iconography       3304\n",
      "Description      16957\n",
      "image_path       20516\n",
      "Object Number    20522\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the number of unique values in each column and sort them\n",
    "unique_values = df.nunique().sort_values()\n",
    "\n",
    "# Display the sorted number of unique values for each column\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de9faf",
   "metadata": {},
   "source": [
    "Provenience is most commonly related to\n",
    "\n",
    "Section: This might provide geographical context within a broader archaeological site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b98b8609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Provenience': 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Section' to find the mode for 'Provenience'\n",
    "provenience_mode = df.groupby(['Section'])['Provenience'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Provenience' values using the mode of the corresponding 'Section' group\n",
    "df['Provenience'] = df.apply(\n",
    "    lambda row: provenience_mode.get(row['Section'], row['Provenience']) \n",
    "    if pd.isna(row['Provenience']) else row['Provenience'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Provenience' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Provenience':\", df['Provenience'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394212f9",
   "metadata": {},
   "source": [
    "Now let's look at materials\n",
    "\n",
    "Material could be dependent on culture and period\n",
    "\n",
    "Culture: The type of material used could be strongly related to the culture. For example, different cultures may have preferred materials based on their environment, technological capabilities, or artistic traditions. For instance, the Totonac culture might be associated with specific materials like Lava Stone or other local materials.\n",
    "\n",
    "Period: The time period in which the artifact was made could also influence the material used. For example, certain materials might have been more common in specific time periods (e.g., Lava Stone in the Late Classic period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eb912276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Materials': 229\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Period' and 'Culture' to find the mode for 'Materials'\n",
    "materials_mode = df.groupby(['Period', 'Culture'])['Materials'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Materials' values using the mode of the corresponding 'Period' and 'Culture' group\n",
    "df['Materials'] = df.apply(\n",
    "    lambda row: materials_mode.get((row['Period'], row['Culture']), row['Materials']) \n",
    "    if pd.isna(row['Materials']) else row['Materials'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Materials' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Materials':\", df['Materials'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "346746f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Materials': 41\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Provenience' to find the mode for 'Materials'\n",
    "# This assumes that 'Materials' might be related to 'Provenience'\n",
    "materials_mode = df.groupby(['Provenience'])['Materials'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Materials' values using the mode of the corresponding 'Provenience' group\n",
    "df['Materials'] = df.apply(\n",
    "    lambda row: materials_mode.get(row['Provenience'], row['Materials']) \n",
    "    if pd.isna(row['Materials']) and pd.notna(row['Provenience']) else row['Materials'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Materials' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Materials':\", df['Materials'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2809e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Materials': 26\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Date Made' to find the mode for 'Materials'\n",
    "# This assumes that 'Materials' might be related to 'Date Made'\n",
    "materials_mode = df.groupby(['Date Made'])['Materials'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Materials' values using the mode of the corresponding 'Date Made' group\n",
    "df['Materials'] = df.apply(\n",
    "    lambda row: materials_mode.get(row['Date Made'], row['Materials']) \n",
    "    if pd.isna(row['Materials']) and pd.notna(row['Date Made']) else row['Materials'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Materials' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Materials':\", df['Materials'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fd6e0c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Materials': 26\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Iconography' to find the mode for 'Materials'\n",
    "# This assumes that the 'Materials' are related to 'Iconography'\n",
    "materials_mode = df.groupby(['Iconography'])['Materials'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Materials' values using the mode of the corresponding 'Iconography' group\n",
    "df['Materials'] = df.apply(\n",
    "    lambda row: materials_mode.get(row['Iconography'], row['Materials']) \n",
    "    if pd.isna(row['Materials']) and pd.notna(row['Iconography']) else row['Materials'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Materials' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Materials':\", df['Materials'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738fc54",
   "metadata": {},
   "source": [
    "Seems like this is the best we can do. Let's make another category called unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4d9d7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Materials': 0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'Materials' values with 'Unknown'\n",
    "df['Materials'] = df['Materials'].fillna('Unknown')\n",
    "\n",
    "# Check how many null values remain in 'Materials'\n",
    "print(\"\\nNumber of remaining null values in 'Materials':\", df['Materials'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3b294053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where nothing is null: 53\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in the row are not null in df\n",
    "non_null_rows = df.notna().all(axis=1)\n",
    "\n",
    "# Get the rows where nothing is null\n",
    "rows_with_no_nulls = df[non_null_rows]\n",
    "\n",
    "# Display the number of rows where nothing is null\n",
    "print(f\"Number of rows where nothing is null: {len(rows_with_no_nulls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "55779fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object Number        0\n",
       "image_path           0\n",
       "Culture Area     12943\n",
       "Culture          10140\n",
       "Date Made         8374\n",
       "Description          0\n",
       "Iconography      12734\n",
       "Materials            0\n",
       "Object Title         0\n",
       "Period           13556\n",
       "Provenience          0\n",
       "Section              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745e2b1",
   "metadata": {},
   "source": [
    "Now let's try to fill in Date Made\n",
    "\n",
    "We can assume that Date Made is very much related to Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8ea7595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Date Made': 7108\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Period' to find the mode for 'Date Made'\n",
    "date_made_mode = df.groupby(['Period'])['Date Made'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Date Made' values using the mode of the corresponding 'Period' group\n",
    "df['Date Made'] = df.apply(\n",
    "    lambda row: date_made_mode.get(row['Period'], row['Date Made']) \n",
    "    if pd.isna(row['Date Made']) else row['Date Made'],  # Fill 'Date Made', not 'Materials'\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Date Made' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Date Made':\", df['Date Made'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8360ded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Date Made': 5211\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Culture Area' and 'Culture' to find the mode for 'Date Made'\n",
    "date_made_mode = df.groupby(['Culture Area', 'Culture'])['Date Made'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Date Made' values using the mode of the corresponding 'Culture Area' and 'Culture' group\n",
    "df['Date Made'] = df.apply(\n",
    "    lambda row: date_made_mode.get((row['Culture Area'], row['Culture']), row['Date Made']) \n",
    "    if pd.isna(row['Date Made']) else row['Date Made'],  # Fill 'Date Made', not 'Materials'\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Date Made' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Date Made':\", df['Date Made'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e88556c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where nothing is null: 97\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in the row are not null in df2\n",
    "non_null_rows = df.notna().all(axis=1)\n",
    "\n",
    "# Get the rows where nothing is null\n",
    "rows_with_no_nulls = df[non_null_rows]\n",
    "\n",
    "# Display the number of rows where nothing is null\n",
    "print(f\"Number of rows where nothing is null: {len(rows_with_no_nulls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0a70f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object Number        0\n",
       "image_path           0\n",
       "Culture Area     12943\n",
       "Culture          10140\n",
       "Date Made         5211\n",
       "Description          0\n",
       "Iconography      12734\n",
       "Materials            0\n",
       "Object Title         0\n",
       "Period           13556\n",
       "Provenience          0\n",
       "Section              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd676d",
   "metadata": {},
   "source": [
    "Now let's look at Period null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e50ce101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Period': 8016\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Date Made' to find the mode for 'Period'\n",
    "period_mode = df.groupby(['Date Made'])['Period'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Period' values using the mode of the corresponding 'Date Made' group\n",
    "df['Period'] = df.apply(\n",
    "    lambda row: period_mode.get(row['Date Made'], row['Period']) \n",
    "    if pd.isna(row['Period']) else row['Period'],  # Fill 'Period', not 'Date Made'\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Period' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Period':\", df['Period'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9da4cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Period': 7506\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Culture Area' and 'Culture' to find the mode for 'Period'\n",
    "period_mode = df.groupby(['Culture Area', 'Culture'])['Period'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Period' values using the mode of the corresponding 'Culture Area' and 'Culture' group\n",
    "df['Period'] = df.apply(\n",
    "    lambda row: period_mode.get((row['Culture Area'], row['Culture']), row['Period']) \n",
    "    if pd.isna(row['Period']) else row['Period'],  # Fill 'Period', not 'Culture Area' or 'Culture'\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Period' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Period':\", df['Period'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a2bc8543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object Number        0\n",
       "image_path           0\n",
       "Culture Area     12943\n",
       "Culture          10140\n",
       "Date Made         5211\n",
       "Description          0\n",
       "Iconography      12734\n",
       "Materials            0\n",
       "Object Title         0\n",
       "Period            7506\n",
       "Provenience          0\n",
       "Section              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49164ba",
   "metadata": {},
   "source": [
    "Let's look at culture and culture areas now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "efb326d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Culture Area': 12560\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Culture' to find the mode for 'Culture Area'\n",
    "culture_area_mode = df.groupby(['Culture'])['Culture Area'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Culture Area' values using the mode of the corresponding 'Culture' group\n",
    "df['Culture Area'] = df.apply(\n",
    "    lambda row: culture_area_mode.get(row['Culture'], row['Culture Area']) \n",
    "    if pd.isna(row['Culture Area']) else row['Culture Area'],  # Fill 'Culture Area', not 'Culture'\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Culture Area' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Culture Area':\", df['Culture Area'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e1a97efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Culture': 6455\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Culture Area' to find the mode for 'Culture'\n",
    "culture_mode = df.groupby(['Culture Area'])['Culture'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Culture' values using the mode of the corresponding 'Culture Area' group\n",
    "df['Culture'] = df.apply(\n",
    "    lambda row: culture_mode.get(row['Culture Area'], row['Culture']) \n",
    "    if pd.isna(row['Culture']) else row['Culture'],  # Fill 'Culture', not 'Culture Area'\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Culture' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Culture':\", df['Culture'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dc39cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where nothing is null: 951\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in the row are not null in df2\n",
    "non_null_rows = df.notna().all(axis=1)\n",
    "\n",
    "# Get the rows where nothing is null\n",
    "rows_with_no_nulls = df[non_null_rows]\n",
    "\n",
    "# Display the number of rows where nothing is null\n",
    "print(f\"Number of rows where nothing is null: {len(rows_with_no_nulls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77090204",
   "metadata": {},
   "source": [
    "Let's try to fill in iconography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7ce9db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of remaining null values in 'Iconography': 9364\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Culture' and 'Period' to find the mode for 'Iconography'\n",
    "iconography_mode = df.groupby(['Culture', 'Period'])['Iconography'].agg(\n",
    "    lambda x: x.mode()[0] if not x.mode().empty else None\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing 'Iconography' values using the mode of the corresponding 'Culture' and 'Period' group\n",
    "df['Iconography'] = df.apply(\n",
    "    lambda row: iconography_mode.get((row['Culture'], row['Period']), row['Iconography']) \n",
    "    if pd.isna(row['Iconography']) else row['Iconography'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally check how many null values remain in 'Iconography' after filling\n",
    "print(\"\\nNumber of remaining null values in 'Iconography':\", df['Iconography'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3296e",
   "metadata": {},
   "source": [
    "We still have a lot of null values for iconography, let's drop and see how many rows are full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1c82631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Iconography'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "47ef42df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where nothing is null: 4143\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in the row are not null in df2\n",
    "non_null_rows = df.notna().all(axis=1)\n",
    "\n",
    "# Get the rows where nothing is null\n",
    "rows_with_no_nulls = df[non_null_rows]\n",
    "\n",
    "# Display the number of rows where nothing is null\n",
    "print(f\"Number of rows where nothing is null: {len(rows_with_no_nulls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "98565b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4143, 11)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_no_nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f0cc27aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object Number    0\n",
       "image_path       0\n",
       "Culture Area     0\n",
       "Culture          0\n",
       "Date Made        0\n",
       "Description      0\n",
       "Materials        0\n",
       "Object Title     0\n",
       "Period           0\n",
       "Provenience      0\n",
       "Section          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_no_nulls.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "27866cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Section             5\n",
       "Culture Area       36\n",
       "Period            117\n",
       "Culture           291\n",
       "Date Made         373\n",
       "Provenience       927\n",
       "Object Title      950\n",
       "Materials        1073\n",
       "Description      3730\n",
       "image_path       4121\n",
       "Object Number    4122\n",
       "dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_no_nulls.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3cdc5948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing duplicates: 4121\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'image_path' is duplicated (i.e., keep only unique image paths)\n",
    "final_df = rows_with_no_nulls.drop_duplicates(subset='image_path', keep='first')\n",
    "\n",
    "# Check the result\n",
    "print(f\"Number of rows after removing duplicates: {final_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8d7de747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Section             5\n",
       "Culture Area       36\n",
       "Period            117\n",
       "Culture           291\n",
       "Date Made         372\n",
       "Provenience       927\n",
       "Object Title      948\n",
       "Materials        1070\n",
       "Description      3721\n",
       "Object Number    4100\n",
       "image_path       4121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "61eaac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
