# Evaluation on processed dataset


```bash
    cd models/gemini_pro
    python ../../models/eval_script/bleu_score_evaluation.py results_processed_data.json
```

Average BLEU Score: 6.139735556909032e-05


```bash
    cd models/gemini_pro
    python ../../models/eval_script/metric_score_evaluation.py results_processed_data.json
```

Average F1 score: 0.0244
Average Precision: 0.0166
Average Recall: 0.0996
